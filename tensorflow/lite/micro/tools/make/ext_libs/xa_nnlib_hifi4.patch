diff --git a/algo/kernels/basic/hifi4/xa_nn_elm_quantize.c b/algo/kernels/basic/hifi4/xa_nn_elm_quantize.c
index 589e97e..a9e6bf3 100644
--- a/algo/kernels/basic/hifi4/xa_nn_elm_quantize.c
+++ b/algo/kernels/basic/hifi4/xa_nn_elm_quantize.c
@@ -450,14 +450,14 @@ WORD32 xa_nn_elm_requantize_asym8s_asym32s(WORD32 * __restrict__ p_out,
   for(i = 0; i < (num_elm & 7); i++)
   {
     ae_int16x4 d_inp0 = (WORD16)*p_i;
-    ae_int32x2 d_inp32_0 = 0;
+    ae_int32x2 d_inp32_0 = 0, d_inp32_1 = 0;
 
     d_inp0 = AE_SUB16(d_inp0, d_inp_zero_bias);
 
 #if XCHAL_HAVE_HIFI1
     d_inp32_0 = AE_SEXT32X2D16_32(d_inp0);
 #else
-    AE_MUL16X4(d_inp32_0, d_inp32_0, d_inp0, ONE); 
+    AE_MUL16X4(d_inp32_0, d_inp32_1, d_inp0, ONE);
 #endif
 
     MPY_BY_QUANT_MULT_SLS_X2_OUT32(d_inp32_0, d_inp32_0, d_out_multiplier, left_shift, right_shift);
@@ -1058,7 +1058,7 @@ WORD32 xa_nn_elm_requantize_asym8s_asym8u(UWORD8 * __restrict__ p_out,
   {   
     ae_int16x4 d_inp0 = (WORD16)*p_i;
     d_inp0 = AE_SUB16(d_inp0, d_inp_zero_bias);
-    AE_MUL16X4(d_inp32_0 , d_inp32_0 , d_inp0 , ONE);
+    AE_MUL16X4(d_inp32_0 , d_inp32_1 , d_inp0 , ONE);
     MPY_BY_QUANT_MULT_SLS_X2_OUT32(d_out0_32, d_inp32_0, out_multiplier, left_shift, right_shift);
     d_out0_32 = AE_ADD32S(d_out0_32, AE_MOVDA32(out_zero_bias));
     CLAMP_VAL(d_out0_32, d_out0_32, d_min, AE_MOVDA32(255))
@@ -1177,7 +1177,7 @@ WORD32 xa_nn_elm_requantize_asym8s_asym8u(UWORD8 * __restrict__ p_out,
   {   
     ae_int16x4 d_inp0 = (WORD16)*p_i;
     d_inp0 = AE_SUB16(d_inp0, d_inp_zero_bias);
-    AE_MUL16X4(d_inp32_0 , d_inp32_0 , d_inp0 , ONE);
+    AE_MUL16X4(d_inp32_0 , d_inp32_1 , d_inp0 , ONE);
     MPY_BY_QUANT_MULT_SLS_X2_OUT32(d_out0_32, d_inp32_0, out_multiplier, left_shift, right_shift);
     d_out0_32 = AE_ADD32S(d_out0_32, AE_MOVDA32(out_zero_bias));
     CLAMP_VAL(d_out0_32, d_out0_32, d_min, AE_MOVDA32(255))
diff --git a/algo/kernels/activations/hifi4/xa_nn_activations_asym16_asym16.c b/algo/kernels/activations/hifi4/xa_nn_activations_asym16_asym16.c
index e5fb930..9816615 100644
--- a/algo/kernels/activations/hifi4/xa_nn_activations_asym16_asym16.c
+++ b/algo/kernels/activations/hifi4/xa_nn_activations_asym16_asym16.c
@@ -63,7 +63,6 @@ WORD32 xa_nn_vec_leaky_relu_asym16s_asym16s( WORD16 * __restrict__ p_out,
   XA_NNLIB_ARG_CHK_COND(((inp_zero_bias < -32768) || (inp_zero_bias > 32767)), -1);
   XA_NNLIB_ARG_CHK_COND(((out_shift < -31) || (out_shift > 31)), -1);
   XA_NNLIB_ARG_CHK_COND(((alpha_shift < -31) || (alpha_shift > 31)), -1);
-  XA_NNLIB_ARG_CHK_COND((alpha_multiplier < 0), -1);
   XA_NNLIB_ARG_CHK_COND((out_multiplier < 0), -1);
   XA_NNLIB_ARG_CHK_COND(((out_zero_bias < -32768) || (out_zero_bias > 32767)), -1);
 
diff --git a/algo/kernels/activations/hifi4/xa_nn_activations_asym8_asym8.c b/algo/kernels/activations/hifi4/xa_nn_activations_asym8_asym8.c
index 07336bd..a3d2862 100644
--- a/algo/kernels/activations/hifi4/xa_nn_activations_asym8_asym8.c
+++ b/algo/kernels/activations/hifi4/xa_nn_activations_asym8_asym8.c
@@ -1490,7 +1490,6 @@ WORD32 xa_nn_vec_leaky_relu_asym8s_asym8s( WORD8 * __restrict__ p_out,
   XA_NNLIB_ARG_CHK_COND(((inp_zero_bias < -128) || (inp_zero_bias > 127)), -1);
   XA_NNLIB_ARG_CHK_COND(((out_shift < -31) || (out_shift > 31)), -1);
   XA_NNLIB_ARG_CHK_COND(((alpha_shift < -31) || (alpha_shift > 31)), -1);
-  XA_NNLIB_ARG_CHK_COND((alpha_multiplier < 0), -1);
   XA_NNLIB_ARG_CHK_COND((out_multiplier < 0), -1);
   XA_NNLIB_ARG_CHK_COND(((out_zero_bias < -128) || (out_zero_bias > 127)), -1);
 
diff --git a/algo/kernels/basic/hifi4/xa_nn_elm_add_quant8.c b/algo/kernels/basic/hifi4/xa_nn_elm_add_quant8.c
index d69744b..5f588a5 100644
--- a/algo/kernels/basic/hifi4/xa_nn_elm_add_quant8.c
+++ b/algo/kernels/basic/hifi4/xa_nn_elm_add_quant8.c
@@ -1826,6 +1826,48 @@ WORD32 xa_nn_elm_add_broadcast_4D_asym8sxasym8s_asym8s(WORD8 * __restrict__ p_ou
                 1,
                 p_out_shape[0] * inp1_strides[0]);
   }
+  else if(inp1_const == 1 || inp2_const == 1)
+  {
+    WORD32 inp1_zb, inp1_ls, inp1_mult;
+    WORD32 inp2_zb, inp2_ls, inp2_mult;
+    inp1_zb = inp1_zero_bias;
+    inp1_ls = inp1_left_shift;
+    inp1_mult = inp1_multiplier;
+    inp2_zb = inp2_zero_bias;
+    inp2_ls = inp2_left_shift;
+    inp2_mult = inp2_multiplier;
+    if(inp1_const == 1)
+    {
+      inp2_zb = inp1_zero_bias;
+      inp2_ls = inp1_left_shift;
+      inp2_mult = inp1_multiplier;
+      inp1_zb = inp2_zero_bias;
+      inp1_ls = inp2_left_shift;
+      inp1_mult = inp2_multiplier;
+
+      const WORD8 *tmp;
+      tmp = p_inp1_tmp;   p_inp1_tmp = p_inp2_tmp;    p_inp2_tmp = tmp;
+    }
+    {
+      internal_elm_add_broadcast_asym8sxasym8s_asym8s(
+          p_out_tmp,
+          out_zero_bias,
+          out_left_shift,
+          out_multiplier,
+          out_activation_min,
+          out_activation_max,
+          p_inp1_tmp,
+          inp1_zb,
+          inp1_ls,
+          inp1_mult,
+          p_inp2_tmp,
+          inp2_zb,
+          inp2_ls,
+          inp2_mult,
+          left_shift,
+          p_out_shape[0] * p_out_shape[1] * p_out_shape[2] * p_out_shape[3]);
+    }
+  }
   else if(inp1_strides[3] == inp2_strides[3])
   {
     WORD32 in_lc, out_lc;
@@ -1902,48 +1944,6 @@ WORD32 xa_nn_elm_add_broadcast_4D_asym8sxasym8s_asym8s(WORD8 * __restrict__ p_ou
       p_inp2_tmp += inp2_strides[0];
     }
   }
-  else if(inp1_const == 1 || inp2_const == 1)
-  {
-    WORD32 inp1_zb, inp1_ls, inp1_mult;
-    WORD32 inp2_zb, inp2_ls, inp2_mult;
-    inp1_zb = inp1_zero_bias;
-    inp1_ls = inp1_left_shift;
-    inp1_mult = inp1_multiplier;
-    inp2_zb = inp2_zero_bias;
-    inp2_ls = inp2_left_shift;
-    inp2_mult = inp2_multiplier;
-    if(inp1_const == 1)
-    {
-      inp2_zb = inp1_zero_bias;
-      inp2_ls = inp1_left_shift;
-      inp2_mult = inp1_multiplier;
-      inp1_zb = inp2_zero_bias;
-      inp1_ls = inp2_left_shift;
-      inp1_mult = inp2_multiplier;
-
-      const WORD8 *tmp;
-      tmp = p_inp1_tmp;   p_inp1_tmp = p_inp2_tmp;    p_inp2_tmp = tmp;
-    }
-    {
-      internal_elm_add_broadcast_asym8sxasym8s_asym8s(
-          p_out_tmp,
-          out_zero_bias,
-          out_left_shift,
-          out_multiplier,
-          out_activation_min,
-          out_activation_max,
-          p_inp1_tmp,
-          inp1_zb,
-          inp1_ls,
-          inp1_mult,
-          p_inp2_tmp,
-          inp2_zb,
-          inp2_ls,
-          inp2_mult,
-          left_shift,
-          p_out_shape[0] * p_out_shape[1] * p_out_shape[2] * p_out_shape[3]);
-    }
-  }
   else
   {
     WORD32 inp1_zb, inp1_ls, inp1_mult;
diff --git a/algo/kernels/basic/hifi4/xa_nn_elm_mul_quant8.c b/algo/kernels/basic/hifi4/xa_nn_elm_mul_quant8.c
index 770f00b..6abcc91 100644
--- a/algo/kernels/basic/hifi4/xa_nn_elm_mul_quant8.c
+++ b/algo/kernels/basic/hifi4/xa_nn_elm_mul_quant8.c
@@ -1525,6 +1525,33 @@ WORD32 xa_nn_elm_mul_broadcast_4D_asym8sxasym8s_asym8s(WORD8 * __restrict__ p_ou
                 1,
                 p_out_shape[0] * inp1_strides[0]);
   }
+  else if(inp1_const == 1 || inp2_const == 1)
+  {
+    WORD32 inp1_zb;
+    WORD32 inp2_zb;
+    inp1_zb = inp1_zero_bias;
+    inp2_zb = inp2_zero_bias;
+    if(inp1_const == 1)
+    {
+      inp2_zb = inp1_zero_bias;
+      inp1_zb = inp2_zero_bias;
+      const WORD8 *tmp;
+      tmp = p_inp1_tmp;   p_inp1_tmp = p_inp2_tmp;    p_inp2_tmp = tmp;
+    }
+
+    internal_elm_mul_broadcast_asym8sxasym8s_asym8s(
+        p_out_tmp,
+        out_zero_bias,
+        out_shift,
+        out_multiplier,
+        out_activation_min,
+        out_activation_max,
+        p_inp1_tmp,
+        inp1_zb,
+        p_inp2_tmp,
+        inp2_zb,
+        p_out_shape[0] * p_out_shape[1] * p_out_shape[2] * p_out_shape[3]);
+  }
   else if(inp1_strides[3] == inp2_strides[3])
   {
     WORD32 in_lc, out_lc;
@@ -1588,33 +1615,6 @@ WORD32 xa_nn_elm_mul_broadcast_4D_asym8sxasym8s_asym8s(WORD8 * __restrict__ p_ou
       p_inp2_tmp += inp2_strides[0];
     }
   }
-  else if(inp1_const == 1 || inp2_const == 1)
-  {
-    WORD32 inp1_zb;
-    WORD32 inp2_zb;
-    inp1_zb = inp1_zero_bias;
-    inp2_zb = inp2_zero_bias;
-    if(inp1_strides[3] == 0)
-    {
-      inp2_zb = inp1_zero_bias;
-      inp1_zb = inp2_zero_bias;
-      const WORD8 *tmp;
-      tmp = p_inp1_tmp;   p_inp1_tmp = p_inp2_tmp;    p_inp2_tmp = tmp;
-    }
-
-    internal_elm_mul_broadcast_asym8sxasym8s_asym8s(
-        p_out_tmp,
-        out_zero_bias,
-        out_shift,
-        out_multiplier,
-        out_activation_min,
-        out_activation_max,
-        p_inp1_tmp,
-        inp1_zb,
-        p_inp2_tmp,
-        inp2_zb,
-        p_out_shape[0] * p_out_shape[1] * p_out_shape[2] * p_out_shape[3]);
-  }
   else
   {
     WORD32 inp1_zb;
diff --git a/algo/kernels/basic/hifi4/xa_nn_elm_squared_diff_quant8.c b/algo/kernels/basic/hifi4/xa_nn_elm_squared_diff_quant8.c
index e7e3858..78041c8 100644
--- a/algo/kernels/basic/hifi4/xa_nn_elm_squared_diff_quant8.c
+++ b/algo/kernels/basic/hifi4/xa_nn_elm_squared_diff_quant8.c
@@ -637,6 +637,46 @@ WORD32 xa_nn_elm_squared_diff_broadcast_4D_asym8sxasym8s_asym8s(WORD8 * __restri
                 1,
                 p_out_shape[0] * inp1_strides[0]);
   }
+  else if(inp1_const == 1 || inp2_const == 1)
+  {
+    WORD32 inp1_zb, inp1_ls, inp1_mult;
+    WORD32 inp2_zb, inp2_ls, inp2_mult;
+    inp1_zb = inp1_zero_bias;
+    inp1_ls = inp1_left_shift;
+    inp1_mult = inp1_multiplier;
+    inp2_zb = inp2_zero_bias;
+    inp2_ls = inp2_left_shift;
+    inp2_mult = inp2_multiplier;
+    /* Reversing the inputs is okay because difference is squared */
+    if(inp1_const == 1)
+    {
+      inp2_zb = inp1_zero_bias;
+      inp2_ls = inp1_left_shift;
+      inp2_mult = inp1_multiplier;
+      inp1_zb = inp2_zero_bias;
+      inp1_ls = inp2_left_shift;
+      inp1_mult = inp2_multiplier;
+      const WORD8 *tmp;
+      tmp = p_inp1_tmp;   p_inp1_tmp = p_inp2_tmp;    p_inp2_tmp = tmp;
+    }
+    internal_elm_squared_diff_broadcast_asym8sxasym8s_asym8s(
+        p_out_tmp,
+        out_zero_bias,
+        out_left_shift,
+        out_multiplier,
+        out_activation_min,
+        out_activation_max,
+        p_inp1_tmp,
+        inp1_zb,
+        inp1_ls,
+        inp1_mult,
+        p_inp2_tmp,
+        inp2_zb,
+        inp2_ls,
+        inp2_mult,
+        left_shift,
+        p_out_shape[0] * p_out_shape[1] * p_out_shape[2] * p_out_shape[3]);
+  }
   else if(inp1_strides[3] == inp2_strides[3])
   {
     WORD32 in_lc, out_lc;
@@ -713,46 +753,6 @@ WORD32 xa_nn_elm_squared_diff_broadcast_4D_asym8sxasym8s_asym8s(WORD8 * __restri
       p_inp2_tmp += inp2_strides[0];
     }
   }
-  else if(inp1_const == 1 || inp2_const == 1)
-  {
-    WORD32 inp1_zb, inp1_ls, inp1_mult;
-    WORD32 inp2_zb, inp2_ls, inp2_mult;
-    inp1_zb = inp1_zero_bias;
-    inp1_ls = inp1_left_shift;
-    inp1_mult = inp1_multiplier;
-    inp2_zb = inp2_zero_bias;
-    inp2_ls = inp2_left_shift;
-    inp2_mult = inp2_multiplier;
-    /* Reversing the inputs is okay because difference is squared */
-    if(inp1_strides[3] == 0)
-    {
-      inp2_zb = inp1_zero_bias;
-      inp2_ls = inp1_left_shift;
-      inp2_mult = inp1_multiplier;
-      inp1_zb = inp2_zero_bias;
-      inp1_ls = inp2_left_shift;
-      inp1_mult = inp2_multiplier;
-      const WORD8 *tmp;
-      tmp = p_inp1_tmp;   p_inp1_tmp = p_inp2_tmp;    p_inp2_tmp = tmp;
-    }
-    internal_elm_squared_diff_broadcast_asym8sxasym8s_asym8s(
-        p_out_tmp,
-        out_zero_bias,
-        out_left_shift,
-        out_multiplier,
-        out_activation_min,
-        out_activation_max,
-        p_inp1_tmp,
-        inp1_zb,
-        inp1_ls,
-        inp1_mult,
-        p_inp2_tmp,
-        inp2_zb,
-        inp2_ls,
-        inp2_mult,
-        left_shift,
-        p_out_shape[0] * p_out_shape[1] * p_out_shape[2] * p_out_shape[3]);
-  }
   else
   {
     WORD32 inp1_zb, inp1_ls, inp1_mult;
